# README
## Separate Images Into Two Clusters
1. Use [this tool](https://github.com/hlzz/libvot). Following the readme of libvot, you'll obtain `image_list` which contains paths to all images, and `match.out` which contains information of image similarity. 
2. Using `decomposition.py` to separate images into two cluster.
Usage:
    ```
    $ python3 decomposition.py \
        --match <path to `match.out`> \
        --img_list <path to `image_list`>
    ```
    This code will automatically generate a folder in the same place of `src`, called `test`. Inside `test`, there will be two folders, i.e., `block1` and `block2`. All images will be separate into two clusters and placed in these two folder. Additionally, there will be a folder called `anchor` in both `block1` and `block2`, which contains a set of anchor images. Anchor images in these two clusters are identical.
    
**Notes: If the separate result is bad or not reasonable, you can separate the images into two clusters by yourself manually.**
    
## 3D Reconstruction
Use [COLMAP](https://colmap.github.io/) to build 3D models of the two clusters generated above. 
Some log file generated by COLMAP will be used in the later steps, including `cameras.txt`, `images.txt`, `points3D.txt`, and a `ply` model file. Note that you should convert the `ply` file from binary to ASCII format, and name it `model.ply`.

## Merge Two Sub-model
For convenience, you should create two folders in `test` folder generated in step 1, called `blk1` and `blk2`. Then you can placed the log files generated by COLMAP mentioned above into them.
```
|_src/
|    |_math_fnc/
|    |_utils/
|    |_decomposition.py
|    |_merge_camera.py
|    |_pytransform.py
|    |_Ncut.py
|
|_test/
     |_blk1/
     |    |_cameras.txt
     |    |_images.txt
     |    |_points3D.txt
     |    |_model.ply
     |
     |_blk2/
          |_(same content as blk1)
```

Usage:`$ python3 merge_camera.py` or `$ python3 merge_model.py`

This code will calculate the transformation matrix between block1 and block2, then align block2 with block1 by multiply all 3D points in block by the transformation matrix. A `ply` file called `merged_model_cam.ply` or `merged_model_pnt.ply` will be generated, which is the result of merging the two sub-model.

## Output Explanation
### cam_coor.log
This file will be generated under `test` folder.
Every anchor image that be built in "both" block will be recorded in this file.
Each line contains the information of the anchor images 3d coordinate in both block.
```
# IMAGE_NAME X Y Z U V W
# ex:
anchor/100.jpg	1.003 -0.328 2.500 1.199 0.574 -3.455
```
(X, Y, Z) and (U, V, W) is the 3d coordinate of the anchor image in block1 and block2.
### matchlog.log
This file will be generated under `test` folder. It records the result of warpped anchor images coordinate and the distance to the corresponding anchor images in another block.
```
# IMAGE_NAME [X Y Z] [U V W] L2_DISTANCE
# ex:
anchor/100.jpg [ 1.264  0.576 -3.478] [ 1.199  0.574 -3.455] 0.069
```
(X, Y, Z) is the warpped 3d coordinate of anchor image in block1, (U, V, W) is the original 3d coordinate of anchor image in block2. 
### merged_model.ply
This file will be generated under `test` folder. This is the merged model file, which is based on block2 `model.ply` file with warpped block1 model information appended. You can use tools like `colmap` to view the merged model.
Note that the "element vertex" number in this file is wrong but harmless. You can modify it manually if needed.
### mod_images.txt
This file will be generated under both block folders. It contains the 3d coordinates of all anchor images in that block.
```
# X Y Z IMAGE_NAME
# ex:
1.003 -0.328 2.500 anchor/100.jpg
```
(X, Y, Z) is the 3d coordinate of the anchor image in that block.